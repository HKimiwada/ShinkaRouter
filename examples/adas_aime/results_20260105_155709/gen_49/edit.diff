--- a/original.py
+++ b/original.py
@@ -1,55 +1,95 @@
 """Agent design evaluation on math tasks."""
 
 import re
 from typing import Callable, List, Optional, Tuple, Dict
 from collections import Counter, defaultdict
 from math_eval import agent_evaluation
 
 
 # EVOLVE-BLOCK-START
 class Agent:
-    def __init__(
-        self,
-        query_llm: Callable,
-        temperature=0.0,
-    ):
-        self.output_format_instructions = "On the final line output only the digits of the answer (0‑999). Provide your final answer enclosed in a LaTeX \\boxed{{...}} command."
+    def __init__(self, query_llm: Callable, temperature=0.0):
+        self.output_format_instructions = (
+            "On the final line output only the digits of the answer (0‑999). "
+            "Provide your final answer enclosed in a LaTeX \\boxed{{...}} command."
+        )
         self.query_llm = query_llm
         self.temperature = temperature
 
-    def forward(self, problem: str) -> tuple[str, float]:
-        """Queries the LLM with a math problem."""
+    def forward(self, problem: str) -> Tuple[str, float]:
+        """Queries the LLM with a math problem and iteratively verifies the answer."""
+        # Adjust temperature based on problem complexity
+        self.temperature = 0.7 if "complex" in problem.lower() else 0.0
+
         system_prompt, task_prompt = self.get_prompt_for_task(problem)
         response, cost = self.query_llm(
             prompt=task_prompt,
             system=system_prompt,
             temperature=self.temperature,
         )
+
+        # Iterative verification process
+        response = self.iterative_verification(problem, response)
+
         return response, cost
 
-    def get_prompt_for_task(self, problem: str) -> tuple[str, str]:
-        system_prompt = "You are a skilled mathematician."
-        task_prompt = f"{self.output_format_instructions}:\n\n{problem}\n\n"
+    def iterative_verification(self, problem: str, initial_response: str) -> str:
+        """Refines the initial response through verification."""
+        for _ in range(2):  # Allow two iterations of refinement
+            verification_prompt = (
+                f"Please review your calculations and reasoning for the problem:\n\n"
+                f"{problem}\n\n"
+                f"Your answer is: {initial_response}\n\n"
+                f"Are there any mistakes or areas for improvement? Please explain."
+            )
+            verification_response, _ = self.query_llm(
+                prompt=verification_prompt,
+                system="You are a skilled mathematician.",
+                temperature=self.temperature,
+            )
+            if "mistake" in verification_response.lower():
+                refinement_prompt = (
+                    "Considering the feedback you provided, revise your answer and show your reasoning clearly."
+                )
+                initial_response, _ = self.query_llm(
+                    prompt=refinement_prompt,
+                    system="You are a skilled mathematician.",
+                    temperature=self.temperature,
+                )
+        return initial_response
+
+    def get_prompt_for_task(self, problem: str) -> Tuple[str, str]:
+        system_prompt = "You are a skilled mathematician who provides clarity and structure in explanations."
+        task_prompt = (
+            f"{self.output_format_instructions}:\n\n"
+            f"Here are some examples of similar problems solved step-by-step:\n"
+            f"1. Problem: Find the area of a triangle with base 5 and height 10.\n"
+            f"   Solution: Area = 0.5 * base * height = 0.5 * 5 * 10 = 25.\n"
+            f"2. Problem: What is the sum of angles in a triangle?\n"
+            f"   Solution: The sum is always 180 degrees.\n\n"
+            f"Now please solve the following problem step-by-step:\n\n"
+            f"{problem}\n\n"
+        )
         return system_prompt, task_prompt
 
 
 # EVOLVE-BLOCK-END
 
 
 def run_experiment(**kwargs):
     from utils import query_llm, create_call_limited_query_llm
     from functools import partial
 
     # Create base query_llm function
     base_query_llm = partial(query_llm, model_name=kwargs["model_name"])
 
     # Wrap it with call limiting (max 10 calls per forward pass)
     limited_query_llm = create_call_limited_query_llm(
         base_query_llm,
         max_calls=kwargs["max_calls"],
     )
 
     accuracy, cost_total, processed, num_llm_calls, df = agent_evaluation(
         Agent, limited_query_llm, year=kwargs["year"]
     )
     return accuracy, cost_total, processed, num_llm_calls, df
