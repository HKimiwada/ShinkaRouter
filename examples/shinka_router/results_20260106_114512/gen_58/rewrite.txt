"""ShinkaRouter: Adaptive routing with difficulty classification for AIME problems.

This agent estimates problem difficulty first, then applies tailored reasoning
strategies to optimize accuracy and minimize calls.
"""

import re
from typing import Callable, Tuple, List, Optional
from collections import Counter

class Agent:
    def __init__(
        self,
        query_llm: Callable,
        quick_temp: float = 0.7,
        deep_temp: float = 0.0,
        verify_temp: float = 0.0,
        ensemble_size: int = 3,
    ):
        self.query_llm = query_llm
        self.quick_temp = quick_temp
        self.deep_temp = deep_temp
        self.verify_temp = verify_temp
        self.ensemble_size = ensemble_size
        self._primitive_calls: List[str] = []

        self.output_format = (
            "On the final line output only the digits of the answer (0-999). "
            "Provide your final answer enclosed in a LaTeX \\boxed{{...}} command."
        )

    def _track_call(self, name: str) -> None:
        self._primitive_calls.append(name)

    def get_primitive_calls(self) -> List[str]:
        return self._primitive_calls.copy()

    def reset_tracking(self) -> None:
        self._primitive_calls.clear()

    @staticmethod
    def extract_boxed_answer(response: str) -> Optional[str]:
        idx = response.rfind("\\boxed")
        if idx < 0:
            idx = response.rfind("\\fbox")
        if idx < 0:
            return None
        brace_idx = response.find("{", idx)
        if brace_idx < 0:
            return None
        level = 0
        for i in range(brace_idx, len(response)):
            if response[i] == "{":
                level += 1
            elif response[i] == "}":
                level -= 1
                if level == 0:
                    content = response[brace_idx + 1:i]
                    return content.strip().lstrip("0") or "0"
        return None

    # Primitive methods with consistent prompt structure
    def baseline_solve(self, problem: str) -> Tuple[str, float]:
        self._track_call("baseline_solve")
        prompt = f"{self.output_format}\n\n{problem}\n\n"
        return self.query_llm(prompt, system="You are a skilled mathematician.", temperature=0.0)

    def deep_think(self, problem: str) -> Tuple[str, float]:
        self._track_call("deep_think")
        prompt = (
            f"{self.output_format}\n\n"
            f"Solve this problem carefully with detailed reasoning:\n\n{problem}"
        )
        return self.query_llm(prompt, system="You are an expert mathematician. Think step-by-step, show all reasoning.", temperature=self.deep_temp)

    def verify(self, problem: str, response: str) -> Tuple[str, float]:
        self._track_call("verify")
        prompt = (
            f"{self.output_format}\n\n"
            f"Problem: {problem}\n\n"
            f"Solution:\n{response}\n\n"
            "Verify this solution carefully. If errors are found, correct and finalize."
        )
        return self.query_llm(prompt, system="You are a rigorous mathematics professor.", temperature=self.verify_temp)

    def ensemble_vote(self, problem: str, n: Optional[int] = None) -> Tuple[str, float]:
        self._track_call("ensemble_vote")
        n = n or self.ensemble_size
        prompt = f"{self.output_format}\n\n{problem}\n\n"
        responses = []
        total_cost = 0.0
        for _ in range(n):
            resp, c = self.query_llm(prompt, system="You are a skilled mathematician.", temperature=0.5)
            responses.append(resp)
            total_cost += c
        answers = [self.extract_boxed_answer(r) for r in responses if self.extract_boxed_answer(r)]
        if answers:
            count = Counter(answers)
            winner, _ = count.most_common(1)[0]
            for r in responses:
                if self.extract_boxed_answer(r) == winner:
                    return r, total_cost
        return responses[0], total_cost

    def self_critique(self, problem: str, draft: str) -> Tuple[str, float]:
        self._track_call("self_critique")
        prompt = (
            f"{self.output_format}\n\n"
            f"Problem: {problem}\n\n"
            f"Draft Solution:\n{draft}\n\n"
            "Review and improve this solution if needed."
        )
        return self.query_llm(prompt, system="You are a mathematician reviewing your own work.", temperature=self.deep_temp)

    def estimate_difficulty(self, problem: str) -> Tuple[str, float]:
        self._track_call("estimate_difficulty")
        prompt = (
            f"Analyze this AIME problem and classify its difficulty as 'easy', 'medium', or 'hard'.\n\n"
            f"Problem: {problem}\n\nRespond with exactly one word."
        )
        response, cost = self.query_llm(prompt, system="You are an expert at evaluating AIME problem difficulty.", temperature=0.0)
        diff = response.strip().lower()
        if "easy" in diff:
            return "easy", cost
        elif "hard" in diff:
            return "hard", cost
        else:
            return "medium", cost

    def classify_problem_type(self, problem: str) -> Tuple[str, float]:
        self._track_call("classify_problem_type")
        prompt = (
            f"Classify this AIME problem into one category: algebra, geometry, number_theory, combinatorics, calculus.\n\n"
            f"Problem: {problem}\n\nRespond with one category."
        )
        response, cost = self.query_llm(prompt, system="You are an problem classifier.", temperature=0.0)
        ptype = response.strip().lower().replace(" ", "_")
        for cat in ["algebra", "geometry", "number_theory", "combinatorics", "calculus"]:
            if cat in ptype:
                return cat, cost
        return "algebra", cost

    def forward(self, problem: str) -> Tuple[str, float]:
        """Layered, difficulty-based routing with minimal calls."""
        self.reset_tracking()
        total_cost = 0.0

        # Step 1: Classify difficulty
        diff, c_diff = self.estimate_difficulty(problem)
        total_cost += c_diff

        # For easy: direct baseline + verify
        if diff == "easy":
            resp, c1 = self.baseline_solve(problem)
            total_cost += c1
            vresp, c2 = self.verify(problem, resp)
            total_cost += c2
            return vresp, total_cost

        # For medium: multiple deep_thinks + verify
        elif diff == "medium":
            candidate_resp = None
            candidate_cost = 0.0
            for _ in range(2):  # fewer deep_thinks for efficiency
                resp, c = self.deep_think(problem)
                candidate_resp = resp
                candidate_cost += c
            # pick best candidate (here, last)
            vresp, c_ver = self.verify(problem, candidate_resp)
            total_cost += candidate_cost + c_ver
            return vresp, total_cost

        # For hard: ensemble vote + verify
        else:
            resp, c_e = self.ensemble_vote(problem)
            total_cost += c_e
            vresp, c_ver = self.verify(problem, resp)
            total_cost += c_ver
            return vresp, total_cost