"""ShinkaRouter: Agent with adaptive, difficulty-based routing primitives for AIME problems.

This agent combines difficulty estimation, strategic primitive selection,
and improved voting to enhance accuracy and efficiency. It integrates
the best parts of previous implementations, emphasizing dynamic problem
classification and tailored solution approaches.
"""

import re
from typing import Callable, Tuple, List, Optional
from collections import Counter


class Agent:
    """Agent with adaptive reasoning primitives for AIME problems."""
    def __init__(
        self,
        query_llm: Callable,
        quick_temp: float = 0.7,
        deep_temp: float = 0.0,
        verify_temp: float = 0.0,
        ensemble_size: int = 3,
    ):
        self.query_llm = query_llm
        self.quick_temp = quick_temp
        self.deep_temp = deep_temp
        self.verify_temp = verify_temp
        self.ensemble_size = ensemble_size
        self._primitive_calls: List[str] = []

        self.output_format = (
            "On the final line output only the digits of the answer (0-999). "
            "Provide your final answer enclosed in a LaTeX \\boxed{{...}} command."
        )

    def _track_call(self, primitive_name: str) -> None:
        self._primitive_calls.append(primitive_name)

    def get_primitive_calls(self) -> List[str]:
        return self._primitive_calls.copy()

    def reset_tracking(self) -> None:
        self._primitive_calls = []

    @staticmethod
    def extract_boxed_answer(response: str) -> Optional[str]:
        idx = response.rfind("\\boxed")
        if idx < 0:
            idx = response.rfind("\\fbox")
        if idx < 0:
            return None
        brace_idx = response.find("{", idx)
        if brace_idx < 0:
            return None
        level = 0
        for i in range(brace_idx, len(response)):
            if response[i] == "{":
                level += 1
            elif response[i] == "}":
                level -= 1
                if level == 0:
                    content = response[brace_idx + 1:i]
                    return content.strip().lstrip("0") or "0"
        return None

    # Primitive methods with consistent prompt structure
    def baseline_solve(self, problem: str) -> Tuple[str, float]:
        self._track_call("baseline_solve")
        prompt = f"{self.output_format}:\n\n{problem}\n\n"
        response, cost = self.query_llm(prompt=prompt, system="You are a skilled mathematician.", temperature=0.0)
        return response, cost

    def deep_think(self, problem: str) -> Tuple[str, float]:
        self._track_call("deep_think")
        prompt = (
            f"{self.output_format}\n\n"
            f"Solve this problem carefully with detailed reasoning:\n\n{problem}"
        )
        response, cost = self.query_llm(prompt=prompt, system="You are an expert mathematician. Think step-by-step, showing all reasoning.", temperature=self.deep_temp)
        return response, cost

    def verify(self, problem: str, candidate_response: str) -> Tuple[str, float]:
        self._track_call("verify")
        prompt = (
            f"{self.output_format}\n\n"
            f"Problem: {problem}\n\n"
            f"Student's Solution:\n{candidate_response}\n\n"
            f"Verify this solution. Check each step for errors. Provide the correct final answer."
        )
        response, cost = self.query_llm(prompt=prompt, system="You are a rigorous mathematics professor.", temperature=self.verify_temp)
        return response, cost

    def ensemble_vote(self, problem: str, n: Optional[int] = None) -> Tuple[str, float]:
        self._track_call("ensemble_vote")
        n = n or self.ensemble_size
        prompt = f"{self.output_format}\n\n{problem}\n\n"
        responses = []
        answers = []
        total_cost = 0.0
        ensemble_temp = 0.5  # Lower temp for better consensus
        for _ in range(n):
            resp, c = self.query_llm(prompt=prompt, system="You are a skilled mathematician.", temperature=ensemble_temp)
            responses.append(resp)
            total_cost += c
            ans = self.extract_boxed_answer(resp)
            if ans:
                answers.append(ans)
        if answers:
            count = Counter(answers)
            winner, _ = count.most_common(1)[0]
            for resp in responses:
                if self.extract_boxed_answer(resp) == winner:
                    return resp, total_cost
        return responses[0], total_cost

    def self_critique(self, problem: str, draft_response: str) -> Tuple[str, float]:
        self._track_call("self_critique")
        prompt = (
            f"{self.output_format}\n\n"
            f"Problem: {problem}\n\n"
            f"Draft Solution:\n{draft_response}\n\n"
            f"Review this solution carefully. Check for errors and provide an improved answer."
        )
        response, cost = self.query_llm(prompt=prompt, system="You are a mathematician reviewing your own work.", temperature=self.deep_temp)
        return response, cost

    def estimate_difficulty(self, problem: str) -> Tuple[str, float]:
        self._track_call("estimate_difficulty")
        prompt = (
            f"Analyze this AIME problem and classify its difficulty as 'easy', 'medium', or 'hard'.\n\n"
            f"Problem: {problem}\n\nRespond with exactly one word."
        )
        response, cost = self.query_llm(prompt=prompt, system="You are an expert at evaluating AIME problem difficulty.", temperature=0.0)
        diff = response.strip().lower()
        if "easy" in diff:
            return "easy", cost
        elif "hard" in diff:
            return "hard", cost
        else:
            return "medium", cost

    def classify_problem_type(self, problem: str) -> Tuple[str, float]:
        self._track_call("classify_problem_type")
        prompt = (
            f"Classify this AIME problem into one category: algebra, geometry, number_theory, combinatorics, calculus.\n\n"
            f"Problem: {problem}\n\nRespond with one category."
        )
        response, cost = self.query_llm(prompt=prompt, system="You are an expert at categorizing math problems.", temperature=0.0)
        ptype = response.strip().lower().replace(" ", "_")
        for category in ["algebra", "geometry", "number_theory", "combinatorics", "calculus"]:
            if category in ptype:
                return category, cost
        return "algebra", cost

    # Routing logic based on difficulty estimation
    def forward(self, problem: str) -> Tuple[str, float]:
        self.reset_tracking()
        total_cost = 0.0
        # Step 1: estimate difficulty
        difficulty, diff_cost = self.estimate_difficulty(problem)
        total_cost += diff_cost
        # Step 2: route based on difficulty
        if difficulty == "easy":
            resp, c = self.baseline_solve(problem)
            total_cost += c
            return resp, total_cost
        elif difficulty == "medium":
            resp, c = self.deep_think(problem)
            total_cost += c
            ver_resp, ver_c = self.verify(problem, resp)
            total_cost += ver_c
            return ver_resp, total_cost
        else:
            resp, c = self.ensemble_vote(problem, n=3)
            total_cost += c
            return resp, total_cost